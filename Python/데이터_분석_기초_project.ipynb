{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPH0aj2oJge7TZsXmV3cDnZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chezazyzdzezn/AIFFEL_quest_cr/blob/main/Python/%EB%8D%B0%EC%9D%B4%ED%84%B0_%EB%B6%84%EC%84%9D_%EA%B8%B0%EC%B4%88_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "프로젝트 (2) load_wine : 와인을 분류해 봅시다"
      ],
      "metadata": {
        "id": "gFsNw2uIDmyj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qU7tKu9-B7lk"
      },
      "outputs": [],
      "source": [
        "# 1)필요한 모듈 import하기\n",
        "\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import SGDClassifier, LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2)load_wine 메서드를 사용하여 데이터를 준비\n",
        "# 데이터 준비\n",
        "wine = load_wine()"
      ],
      "metadata": {
        "id": "2UfisgnJCBIY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3)데이터 이해하기\n",
        "# Feature Data 지정하기\n",
        "X = wine.data\n",
        "\n",
        "# Label Data 지정하기\n",
        "y = wine.target\n",
        "\n",
        "# Target Names 출력하기\n",
        "print(\"Target Names:\", wine.target_names)\n",
        "\n",
        "# 데이터 Describe 해 보기\n",
        "import pandas as pd\n",
        "\n",
        "wine_df = pd.DataFrame(X, columns=wine.feature_names)\n",
        "print(wine_df.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRzu26JuCKvk",
        "outputId": "180d563b-f979-4a8b-e025-cbfa2408a208"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target Names: ['class_0' 'class_1' 'class_2']\n",
            "          alcohol  malic_acid         ash  alcalinity_of_ash   magnesium  \\\n",
            "count  178.000000  178.000000  178.000000         178.000000  178.000000   \n",
            "mean    13.000618    2.336348    2.366517          19.494944   99.741573   \n",
            "std      0.811827    1.117146    0.274344           3.339564   14.282484   \n",
            "min     11.030000    0.740000    1.360000          10.600000   70.000000   \n",
            "25%     12.362500    1.602500    2.210000          17.200000   88.000000   \n",
            "50%     13.050000    1.865000    2.360000          19.500000   98.000000   \n",
            "75%     13.677500    3.082500    2.557500          21.500000  107.000000   \n",
            "max     14.830000    5.800000    3.230000          30.000000  162.000000   \n",
            "\n",
            "       total_phenols  flavanoids  nonflavanoid_phenols  proanthocyanins  \\\n",
            "count     178.000000  178.000000            178.000000       178.000000   \n",
            "mean        2.295112    2.029270              0.361854         1.590899   \n",
            "std         0.625851    0.998859              0.124453         0.572359   \n",
            "min         0.980000    0.340000              0.130000         0.410000   \n",
            "25%         1.742500    1.205000              0.270000         1.250000   \n",
            "50%         2.355000    2.135000              0.340000         1.555000   \n",
            "75%         2.800000    2.875000              0.437500         1.950000   \n",
            "max         3.880000    5.080000              0.660000         3.580000   \n",
            "\n",
            "       color_intensity         hue  od280/od315_of_diluted_wines      proline  \n",
            "count       178.000000  178.000000                    178.000000   178.000000  \n",
            "mean          5.058090    0.957449                      2.611685   746.893258  \n",
            "std           2.318286    0.228572                      0.709990   314.907474  \n",
            "min           1.280000    0.480000                      1.270000   278.000000  \n",
            "25%           3.220000    0.782500                      1.937500   500.500000  \n",
            "50%           4.690000    0.965000                      2.780000   673.500000  \n",
            "75%           6.200000    1.120000                      3.170000   985.000000  \n",
            "max          13.000000    1.710000                      4.000000  1680.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4) train, test 데이터 분리\n",
        "# train, test 데이터 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "u-FLFJy5CT96"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5) 다양한 모델로 학습시켜보기\n",
        "# Decision Tree 사용해 보기\n",
        "decision_tree = DecisionTreeClassifier(random_state=42)\n",
        "decision_tree.fit(X_train, y_train)\n",
        "y_pred_dt = decision_tree.predict(X_test)"
      ],
      "metadata": {
        "id": "68ITBULOCY3e"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest 사용해 보기\n",
        "random_forest = RandomForestClassifier(random_state=42)\n",
        "random_forest.fit(X_train, y_train)\n",
        "y_pred_rf = random_forest.predict(X_test)"
      ],
      "metadata": {
        "id": "lE_HiCiwCZUq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM 사용해 보기\n",
        "svm = SVC(random_state=42)\n",
        "svm.fit(X_train, y_train)\n",
        "y_pred_svm = svm.predict(X_test)"
      ],
      "metadata": {
        "id": "Pl1B-v_YChsP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SGD Classifier 사용해 보기\n",
        "sgd = SGDClassifier(random_state=42)\n",
        "sgd.fit(X_train, y_train)\n",
        "y_pred_sgd = sgd.predict(X_test)"
      ],
      "metadata": {
        "id": "FjuABvGxChZb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression 사용해 보기\n",
        "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
        "log_reg.fit(X_train, y_train)\n",
        "y_pred_lr = log_reg.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFhWFnqCChDI",
        "outputId": "54268052-0a52-4716-abd1-5fcb8f96a63c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6) 모델을 평가해 보기\n",
        "# 다양한 평가지표 사용해 보기\n",
        "print(\"Decision Tree Classification Report\")\n",
        "print(classification_report(y_test, y_pred_dt))\n",
        "\n",
        "print(\"Random Forest Classification Report\")\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "\n",
        "print(\"SVM Classification Report\")\n",
        "print(classification_report(y_test, y_pred_svm))\n",
        "\n",
        "print(\"SGD Classifier Classification Report\")\n",
        "print(classification_report(y_test, y_pred_sgd))\n",
        "\n",
        "print(\"Logistic Regression Classification Report\")\n",
        "print(classification_report(y_test, y_pred_lr))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3w-OH2rCmmw",
        "outputId": "b2fb4962-6ff7-4ed0-a09c-ca1e2b09c2b0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.93      0.93        14\n",
            "           1       0.93      1.00      0.97        14\n",
            "           2       1.00      0.88      0.93         8\n",
            "\n",
            "    accuracy                           0.94        36\n",
            "   macro avg       0.95      0.93      0.94        36\n",
            "weighted avg       0.95      0.94      0.94        36\n",
            "\n",
            "Random Forest Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        14\n",
            "           1       1.00      1.00      1.00        14\n",
            "           2       1.00      1.00      1.00         8\n",
            "\n",
            "    accuracy                           1.00        36\n",
            "   macro avg       1.00      1.00      1.00        36\n",
            "weighted avg       1.00      1.00      1.00        36\n",
            "\n",
            "SVM Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        14\n",
            "           1       0.73      0.79      0.76        14\n",
            "           2       0.57      0.50      0.53         8\n",
            "\n",
            "    accuracy                           0.81        36\n",
            "   macro avg       0.77      0.76      0.76        36\n",
            "weighted avg       0.80      0.81      0.80        36\n",
            "\n",
            "SGD Classifier Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.93      0.87        14\n",
            "           1       0.65      0.93      0.76        14\n",
            "           2       0.00      0.00      0.00         8\n",
            "\n",
            "    accuracy                           0.72        36\n",
            "   macro avg       0.49      0.62      0.54        36\n",
            "weighted avg       0.57      0.72      0.63        36\n",
            "\n",
            "Logistic Regression Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.93      0.96        14\n",
            "           1       0.93      1.00      0.97        14\n",
            "           2       1.00      1.00      1.00         8\n",
            "\n",
            "    accuracy                           0.97        36\n",
            "   macro avg       0.98      0.98      0.98        36\n",
            "weighted avg       0.97      0.97      0.97        36\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 성능 평가 지표 선택 이유  \n",
        "\n",
        "정확도(Accuracy): 전체 테스트 데이터 중에서 얼마나 맞췄는지 확인하는 대표적인 지표.  \n",
        "\n",
        "정밀도(Precision): 모델이 양성으로 예측한 것 중 실제 양성의 비율을 나타냅니다.  \n",
        "\n",
        "재현율(Recall): 실제 양성 중에서 모델이 양성으로 정확하게 예측한 비율을 나타냅니다.  \n",
        "\n",
        "F1 Score: 정밀도와 재현율의 조화 평균으로, 불균형한 데이터셋에서 유용합니다."
      ],
      "metadata": {
        "id": "jG1kDp2BHMTt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "프로젝트 (3) load_breast_cancer : 유방암 여부를 진단해 봅시다"
      ],
      "metadata": {
        "id": "Zszs6VTEDqj4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) 필요한 모듈 import하기\n",
        "# 필요한 모듈을 import합니다\n",
        "from sklearn.datasets import load_breast_cancer  # 유방암 데이터셋을 불러오기 위한 메서드\n",
        "from sklearn.model_selection import train_test_split  # 학습/테스트 데이터 분리를 위한 메서드\n",
        "from sklearn.metrics import classification_report  # 모델 성능 평가를 위한 메서드\n",
        "\n",
        "# 사용할 분류 모델들\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import SGDClassifier, LogisticRegression"
      ],
      "metadata": {
        "id": "O3y0urnGDt1o"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) 데이터 준비\n",
        "# 유방암 데이터셋을 불러옵니다\n",
        "cancer = load_breast_cancer()"
      ],
      "metadata": {
        "id": "MZvcnVyfDvDI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) 데이터 이해하기\n",
        "# Feature Data 지정하기 (유방암 데이터의 특징들)\n",
        "X = cancer.data\n",
        "\n",
        "# Label Data 지정하기 (유방암 여부, 양성/악성)\n",
        "y = cancer.target\n",
        "\n",
        "# Target Names 출력하기 (악성, 양성)\n",
        "print(\"Target Names:\", cancer.target_names)\n",
        "\n",
        "# 데이터 Describe 해 보기 (데이터에 대한 기본 통계 정보)\n",
        "import pandas as pd\n",
        "\n",
        "# 데이터를 Pandas DataFrame으로 변환하여 설명 출력\n",
        "cancer_df = pd.DataFrame(X, columns=cancer.feature_names)\n",
        "print(cancer_df.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTaJflmiDu8M",
        "outputId": "c5c3304e-54ea-4cff-a445-beecd9048b8f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target Names: ['malignant' 'benign']\n",
            "       mean radius  mean texture  mean perimeter    mean area  \\\n",
            "count   569.000000    569.000000      569.000000   569.000000   \n",
            "mean     14.127292     19.289649       91.969033   654.889104   \n",
            "std       3.524049      4.301036       24.298981   351.914129   \n",
            "min       6.981000      9.710000       43.790000   143.500000   \n",
            "25%      11.700000     16.170000       75.170000   420.300000   \n",
            "50%      13.370000     18.840000       86.240000   551.100000   \n",
            "75%      15.780000     21.800000      104.100000   782.700000   \n",
            "max      28.110000     39.280000      188.500000  2501.000000   \n",
            "\n",
            "       mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
            "count       569.000000        569.000000      569.000000           569.000000   \n",
            "mean          0.096360          0.104341        0.088799             0.048919   \n",
            "std           0.014064          0.052813        0.079720             0.038803   \n",
            "min           0.052630          0.019380        0.000000             0.000000   \n",
            "25%           0.086370          0.064920        0.029560             0.020310   \n",
            "50%           0.095870          0.092630        0.061540             0.033500   \n",
            "75%           0.105300          0.130400        0.130700             0.074000   \n",
            "max           0.163400          0.345400        0.426800             0.201200   \n",
            "\n",
            "       mean symmetry  mean fractal dimension  ...  worst radius  \\\n",
            "count     569.000000              569.000000  ...    569.000000   \n",
            "mean        0.181162                0.062798  ...     16.269190   \n",
            "std         0.027414                0.007060  ...      4.833242   \n",
            "min         0.106000                0.049960  ...      7.930000   \n",
            "25%         0.161900                0.057700  ...     13.010000   \n",
            "50%         0.179200                0.061540  ...     14.970000   \n",
            "75%         0.195700                0.066120  ...     18.790000   \n",
            "max         0.304000                0.097440  ...     36.040000   \n",
            "\n",
            "       worst texture  worst perimeter   worst area  worst smoothness  \\\n",
            "count     569.000000       569.000000   569.000000        569.000000   \n",
            "mean       25.677223       107.261213   880.583128          0.132369   \n",
            "std         6.146258        33.602542   569.356993          0.022832   \n",
            "min        12.020000        50.410000   185.200000          0.071170   \n",
            "25%        21.080000        84.110000   515.300000          0.116600   \n",
            "50%        25.410000        97.660000   686.500000          0.131300   \n",
            "75%        29.720000       125.400000  1084.000000          0.146000   \n",
            "max        49.540000       251.200000  4254.000000          0.222600   \n",
            "\n",
            "       worst compactness  worst concavity  worst concave points  \\\n",
            "count         569.000000       569.000000            569.000000   \n",
            "mean            0.254265         0.272188              0.114606   \n",
            "std             0.157336         0.208624              0.065732   \n",
            "min             0.027290         0.000000              0.000000   \n",
            "25%             0.147200         0.114500              0.064930   \n",
            "50%             0.211900         0.226700              0.099930   \n",
            "75%             0.339100         0.382900              0.161400   \n",
            "max             1.058000         1.252000              0.291000   \n",
            "\n",
            "       worst symmetry  worst fractal dimension  \n",
            "count      569.000000               569.000000  \n",
            "mean         0.290076                 0.083946  \n",
            "std          0.061867                 0.018061  \n",
            "min          0.156500                 0.055040  \n",
            "25%          0.250400                 0.071460  \n",
            "50%          0.282200                 0.080040  \n",
            "75%          0.317900                 0.092080  \n",
            "max          0.663800                 0.207500  \n",
            "\n",
            "[8 rows x 30 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4) train, test 데이터 분리\n",
        "# 학습 데이터와 테스트 데이터를 분리합니다\n",
        "# train_test_split 함수로 데이터를 80%는 학습용, 20%는 테스트용으로 분리합니다\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "HgB_mmjcDu2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5) 다양한 모델로 학습시켜보기\n",
        "# Decision Tree 모델을 생성하고 학습시킵니다\n",
        "decision_tree = DecisionTreeClassifier(random_state=42)\n",
        "decision_tree.fit(X_train, y_train)\n",
        "\n",
        "# 테스트 데이터로 예측해 봅니다\n",
        "y_pred_dt = decision_tree.predict(X_test)"
      ],
      "metadata": {
        "id": "S8lsw8UtDuv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest 모델을 생성하고 학습시킵니다\n",
        "random_forest = RandomForestClassifier(random_state=42)\n",
        "random_forest.fit(X_train, y_train)\n",
        "\n",
        "# 테스트 데이터로 예측해 봅니다\n",
        "y_pred_rf = random_forest.predict(X_test)"
      ],
      "metadata": {
        "id": "a0KrPCQpDupa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM 모델을 생성하고 학습시킵니다\n",
        "svm = SVC(random_state=42)\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "# 테스트 데이터로 예측해 봅니다\n",
        "y_pred_svm = svm.predict(X_test)"
      ],
      "metadata": {
        "id": "4H6JluU6DujU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SGD Classifier 모델을 생성하고 학습시킵니다\n",
        "sgd = SGDClassifier(random_state=42)\n",
        "sgd.fit(X_train, y_train)\n",
        "\n",
        "# 테스트 데이터로 예측해 봅니다\n",
        "y_pred_sgd = sgd.predict(X_test)"
      ],
      "metadata": {
        "id": "UzqmUho1DucZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression 모델을 생성하고 학습시킵니다\n",
        "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "# 테스트 데이터로 예측해 봅니다\n",
        "y_pred_lr = log_reg.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQo-hDxXDuTS",
        "outputId": "4d642843-2038-47b2-ae42-788cd51d7d28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6) 모델을 평가해 보기\n",
        "# Decision Tree 평가\n",
        "print(\"Decision Tree Classification Report\")\n",
        "print(classification_report(y_test, y_pred_dt))\n",
        "\n",
        "# Random Forest 평가\n",
        "print(\"Random Forest Classification Report\")\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "\n",
        "# SVM 평가\n",
        "print(\"SVM Classification Report\")\n",
        "print(classification_report(y_test, y_pred_svm))\n",
        "\n",
        "# SGD Classifier 평가\n",
        "print(\"SGD Classifier Classification Report\")\n",
        "print(classification_report(y_test, y_pred_sgd))\n",
        "\n",
        "# Logistic Regression 평가\n",
        "print(\"Logistic Regression Classification Report\")\n",
        "print(classification_report(y_test, y_pred_lr))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxmzLIEaG45p",
        "outputId": "dbae3818-29ad-42d1-aa60-c77439be479a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.93      0.93        43\n",
            "           1       0.96      0.96      0.96        71\n",
            "\n",
            "    accuracy                           0.95       114\n",
            "   macro avg       0.94      0.94      0.94       114\n",
            "weighted avg       0.95      0.95      0.95       114\n",
            "\n",
            "Random Forest Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.93      0.95        43\n",
            "           1       0.96      0.99      0.97        71\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.97      0.96      0.96       114\n",
            "weighted avg       0.97      0.96      0.96       114\n",
            "\n",
            "SVM Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.86      0.92        43\n",
            "           1       0.92      1.00      0.96        71\n",
            "\n",
            "    accuracy                           0.95       114\n",
            "   macro avg       0.96      0.93      0.94       114\n",
            "weighted avg       0.95      0.95      0.95       114\n",
            "\n",
            "SGD Classifier Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.74      0.85        43\n",
            "           1       0.87      1.00      0.93        71\n",
            "\n",
            "    accuracy                           0.90       114\n",
            "   macro avg       0.93      0.87      0.89       114\n",
            "weighted avg       0.92      0.90      0.90       114\n",
            "\n",
            "Logistic Regression Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.91      0.94        43\n",
            "           1       0.95      0.99      0.97        71\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.96      0.95      0.95       114\n",
            "weighted avg       0.96      0.96      0.96       114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 성능 평가 지표 선택 이유  \n",
        "\n",
        "정확도(Accuracy): 전체 예측 중 맞춘 비율로, 데이터가 균형잡혀 있을 때 유용한 지표입니다.  \n",
        "\n",
        "정밀도(Precision): 모델이 양성으로 예측한 것 중 실제로 양성인 비율을 나타냅니다. 잘못된 양성 예측을 줄이는 데 중요합니다.  \n",
        "\n",
        "재현율(Recall): 실제 양성 중 모델이 정확히 양성으로 예측한 비율입니다. 놓친 양성 예측을 줄이는 데 유용합니다.  \n",
        "\n",
        "F1 점수: 정밀도와 재현율의 조화 평균으로, 데이터가 불균형할 때 유용한 지표입니다."
      ],
      "metadata": {
        "id": "oyTAR6ZRG9YV"
      }
    }
  ]
}